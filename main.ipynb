{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bffce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211324df",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8079be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(dimensions):\n",
    "    \n",
    "    parametres = {}\n",
    "    C = len(dimensions)\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    for c in range(1, C):\n",
    "        parametres['W' + str(c)] = np.random.randn(dimensions[c], dimensions[c - 1])\n",
    "        parametres['b' + str(c)] = np.random.randn(dimensions[c], 1)\n",
    "\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e41866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parametres):\n",
    "  \n",
    "  activations = {'A0': X}\n",
    "\n",
    "  C = len(parametres) // 2\n",
    "\n",
    "  for c in range(1, C + 1):\n",
    "\n",
    "    Z = parametres['W' + str(c)].dot(activations['A' + str(c - 1)]) + parametres['b' + str(c)]\n",
    "    activations['A' + str(c)] = 1 / (1 + np.exp(-Z))\n",
    "\n",
    "  return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b88fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(y, parametres, activations):\n",
    "\n",
    "  m = y.shape[1]\n",
    "  C = len(parametres) // 2\n",
    "\n",
    "  dZ = activations['A' + str(C)] - y\n",
    "  gradients = {}\n",
    "\n",
    "  for c in reversed(range(1, C + 1)):\n",
    "    gradients['dW' + str(c)] = 1/m * np.dot(dZ, activations['A' + str(c - 1)].T)\n",
    "    gradients['db' + str(c)] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    if c > 1:\n",
    "      dZ = np.dot(parametres['W' + str(c)].T, dZ) * activations['A' + str(c - 1)] * (1 - activations['A' + str(c - 1)])\n",
    "\n",
    "  return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a6f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(gradients, parametres, learning_rate):\n",
    "\n",
    "    C = len(parametres) // 2\n",
    "\n",
    "    for c in range(1, C + 1):\n",
    "        parametres['W' + str(c)] = parametres['W' + str(c)] - learning_rate * gradients['dW' + str(c)]\n",
    "        parametres['b' + str(c)] = parametres['b' + str(c)] - learning_rate * gradients['db' + str(c)]\n",
    "\n",
    "    return parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15e1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parametres):\n",
    "  activations = forward_propagation(X, parametres)\n",
    "  C = len(parametres) // 2\n",
    "  Af = activations['A' + str(C)]\n",
    "  return Af >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17828224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_neural_network(X, y, hidden_layers = (16, 16, 16), learning_rate = 0.001, n_iter = 3000):\n",
    "    \n",
    "    # initialisation parametres\n",
    "    dimensions = list(hidden_layers)\n",
    "    dimensions.insert(0, X.shape[0])\n",
    "    dimensions.append(y.shape[0])\n",
    "    np.random.seed(1)\n",
    "    parametres = initialisation(dimensions)\n",
    "\n",
    "    # tableau numpy contenant les futures accuracy et log_loss\n",
    "    training_history = np.zeros((int(n_iter), 2))\n",
    "\n",
    "    C = len(parametres) // 2\n",
    "\n",
    "    # gradient descent\n",
    "    for i in tqdm(range(n_iter)):\n",
    "\n",
    "        activations = forward_propagation(X, parametres)\n",
    "        gradients = back_propagation(y, parametres, activations)\n",
    "        parametres = update(gradients, parametres, learning_rate)\n",
    "        Af = activations['A' + str(C)]\n",
    "\n",
    "        # calcul du log_loss et de l'accuracy\n",
    "        training_history[i, 0] = (log_loss(y.flatten(), Af.flatten()))\n",
    "        y_pred = predict(X, parametres)\n",
    "        training_history[i, 1] = (accuracy_score(y.flatten(), y_pred.flatten()))\n",
    "\n",
    "    # Plot courbe d'apprentissage\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_history[:, 0], label='train loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_history[:, 1], label='train acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return training_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
